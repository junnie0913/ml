{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHoTJ0MaBjdy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset/avocado.csv')\n",
        "\n",
        "# Drop the 'Unnamed' and 'Date' columns\n",
        "df.drop(columns=['Unnamed: 0', 'Date'], inplace=True)\n",
        "\n",
        "# Handle Missing Values\n",
        "# Numerical columns: impute with mean\n",
        "# Categorical columns: impute with most frequent\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Impute missing values\n",
        "for col in numerical_cols:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "# Convert 'type' column to category if it's not already and apply Label Encoding\n",
        "if 'type' in categorical_cols:\n",
        "    df['type'] = pd.Categorical(df['type'])\n",
        "    df['type'] = df['type'].cat.codes\n",
        "\n",
        "# One-Hot Encoding for the 'region' column\n",
        "df = pd.get_dummies(df, columns=['region'], drop_first=True)\n",
        "\n",
        "# After one-hot encoding, all columns should be numeric.\n",
        "# If any non-numeric columns remain, this would identify them.\n",
        "non_numeric_columns = df.select_dtypes(include=['object']).columns\n",
        "if non_numeric_columns.any():\n",
        "    raise Exception(f\"Non-numeric columns are present: {non_numeric_columns}\")\n",
        "\n",
        "# Handle outliers by replacing them with the mean of the column\n",
        "for col in numerical_cols:\n",
        "    if col != 'type':  # 'type' is now encoded, no longer numerical\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "# Separate features and target variable\n",
        "y = df['AveragePrice']\n",
        "X = df.drop('AveragePrice', axis=1)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Scaling the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Combine the scaled features with the target variable for train and test sets\n",
        "train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "train_df['AveragePrice'] = y_train.reset_index(drop=True)\n",
        "\n",
        "test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "test_df['AveragePrice'] = y_test.reset_index(drop=True)\n",
        "\n",
        "# Save the preprocessed train and test sets into CSV files\n",
        "train_df.to_csv('//content/drive/MyDrive/dataset/train_avocado_1.csv', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/dataset/test_avocado_1.csv', index=False)\n"
      ]
    }
  ]
}